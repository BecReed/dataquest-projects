{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataQuest Guided Project 2: Hacker News \n",
    "\n",
    "This is the second Guided Project from the DataQuest Data Science track. The goal is to explore a data set consisting of submissions to popular technology site, Hacker News; a community based platform for submitting and voting up stories. \n",
    "\n",
    "The data set is available here, https://www.kaggle.com/hacker-news/hacker-news-posts, but has been reduced from almost 300,000 rows to approximately 20,000 rows by removing all submissions that did not receive any comments, and then randomly sampling from the remaining submissions. \n",
    "\n",
    "This guided project covers Python fundamentals so works without NumPy or Pandas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: How Does the Data Set Look?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Review of CSV Import\n",
      "-----\n",
      " [['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'], ['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']]\n"
     ]
    }
   ],
   "source": [
    "from csv import reader \n",
    "openfile = open('hacker_news.csv')\n",
    "readfile = reader(openfile)\n",
    "hn = list(readfile)\n",
    "print('Initial Review of CSV Import\\n-----\\n',hn[0:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headers\n",
      "-------\n",
      " ['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'] \n",
      "\n",
      "First 5 Rows of hn\n",
      "-----\n",
      " [['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01'], ['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "headers = hn[0]\n",
    "hn = hn[1:]\n",
    "print('Headers\\n-------\\n',headers,'\\n')\n",
    "print('First 5 Rows of hn\\n-----\\n', hn[0:5], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Do Ask or Show Posts Get More Comments Overall?\n",
    "\n",
    "First we can seperate the records in the data set by creating a list for the ask posts, a list for the show posts, and a list for any others.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1744\n",
      "1162\n",
      "17194\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    if title.lower().startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif title.lower().startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "        \n",
    "print(len(ask_posts))\n",
    "print(len(show_posts))\n",
    "print(len(other_posts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there are 1744 ask posts, and 1162 show posts in the data set. \n",
    "\n",
    "Next, we can loop through the the ask posts and the show posts respectively and track the number of comments each record has to compute an average number of comments for each category; ask and show. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.038417431192661\n",
      "10.31669535283993\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "for post in ask_posts:\n",
    "    total_ask_comments += int(post[4])\n",
    "avg_ask_comments = total_ask_comments / len(ask_posts)\n",
    "print(avg_ask_comments)\n",
    "\n",
    "total_show_comments = 0\n",
    "for post in show_posts:\n",
    "    total_show_comments += int(post[4])\n",
    "avg_show_comments = total_show_comments / len(show_posts)\n",
    "print(avg_show_comments)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ask posts have an average of 14 comments and the show posts have an average of 10 comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Do Ask Posts Get More Comments At Particular Times of Day?\n",
    "\n",
    "We can look further into the data set to build a dictionary of the number of comments defined on an hour by hour basis. \n",
    "\n",
    "First, for the Ask Posts, we'll build the Average - by - hour data in the format [[ hour1, avg1 ], [ hour2, avg2 ], ...]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9, 5.586956521739131], [13, 14.906976744186046], [10, 13.233333333333333], [14, 13.13888888888889], [16, 16.798165137614678], [23, 7.884057971014493], [12, 9.337837837837839], [17, 11.356435643564357], [15, 38.27350427350427], [21, 15.9], [20, 21.28395061728395], [2, 23.45762711864407], [18, 13.1], [3, 7.672727272727273], [5, 10.48936170212766], [19, 10.72972972972973], [1, 11.737704918032787], [22, 6.680555555555555], [8, 10.142857142857142], [4, 7.083333333333333], [0, 8.160714285714286], [6, 8.844444444444445], [7, 7.685714285714286], [11, 10.898305084745763]]\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "result_list = []\n",
    "for post in ask_posts:\n",
    "    created_at = post[6]\n",
    "    comments = int(post[4])\n",
    "    result_list.append([created_at, comments])\n",
    "\n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "for row in result_list:\n",
    "    hour = row[0]\n",
    "    hour = dt.datetime.strptime(hour, \"%m/%d/%Y %H:%M\")\n",
    "    hour = hour.hour\n",
    "    if hour not in counts_by_hour:\n",
    "        counts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = row[1]\n",
    "    if hour in counts_by_hour:\n",
    "        counts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += row[1]\n",
    "        \n",
    "avg_by_hour = []\n",
    "for hour in comments_by_hour:\n",
    "    avg = comments_by_hour[hour] / counts_by_hour[hour]\n",
    "    avg_by_hour.append([hour, avg])\n",
    "    \n",
    "print(avg_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This doesn't yet make it clear what hours get more or less comment activity so we'll swap the order of the list to be in the formant [[ avg1, hour1 ], [ avg2, hour2 ] ... ] and then sort based on the averages. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.586956521739131, 9], [14.906976744186046, 13], [13.233333333333333, 10], [13.13888888888889, 14], [16.798165137614678, 16], [7.884057971014493, 23], [9.337837837837839, 12], [11.356435643564357, 17], [38.27350427350427, 15], [15.9, 21], [21.28395061728395, 20], [23.45762711864407, 2], [13.1, 18], [7.672727272727273, 3], [10.48936170212766, 5], [10.72972972972973, 19], [11.737704918032787, 1], [6.680555555555555, 22], [10.142857142857142, 8], [7.083333333333333, 4], [8.160714285714286, 0], [8.844444444444445, 6], [7.685714285714286, 7], [10.898305084745763, 11]]\n",
      "[[38.27350427350427, 15], [23.45762711864407, 2], [21.28395061728395, 20], [16.798165137614678, 16], [15.9, 21]]\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "for hour in avg_by_hour:\n",
    "    swap_avg_by_hour.append([hour[1],hour[0]])\n",
    "print(swap_avg_by_hour)\n",
    "sorted_swap = sorted(swap_avg_by_hour, reverse = True )\n",
    "print(sorted_swap[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This view is still hard to read so we'll make a formated string to output the top hours of the day that Ask posts receive comments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:00: 38.27 average comments per post.\n",
      "02:00: 23.46 average comments per post.\n",
      "20:00: 21.28 average comments per post.\n",
      "16:00: 16.80 average comments per post.\n",
      "21:00: 15.90 average comments per post.\n"
     ]
    }
   ],
   "source": [
    "for item in sorted_swap[0:5]:\n",
    "    hour = item[1]\n",
    "    avg = item[0]\n",
    "    hour_dt = dt.datetime.strptime(str(hour), \"%H\")\n",
    "    hour_fm = hour_dt.strftime(\"%H:%M\")\n",
    "    template = \"{h}: {a:.2f} average comments per post.\"\n",
    "    print(template.format(h = hour_fm, a = avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like 3PM is the time of day where Ask posts receive the most comments. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
